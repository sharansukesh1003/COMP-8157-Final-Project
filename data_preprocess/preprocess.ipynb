{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Analysis\n",
    "\n",
    "This notebook preprocesses the dataset by loading, cleaning, normalizing. We focus on calculating minimum, maximum, and range values.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Importing Libraries\n",
    "\n",
    "We use `pandas` for data manipulation, `matplotlib` for plotting, and `statsmodels` for time series analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Inspect Data\n",
    "\n",
    "Load the dataset and inspect its structure. The first column is the \"Page\" identifier, and the remaining columns are date values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Page  2015-07-01  2015-07-02  \\\n",
      "0            2NE1_zh.wikipedia.org_all-access_spider        18.0        11.0   \n",
      "1             2PM_zh.wikipedia.org_all-access_spider        11.0        14.0   \n",
      "2              3C_zh.wikipedia.org_all-access_spider         1.0         0.0   \n",
      "3         4minute_zh.wikipedia.org_all-access_spider        35.0        13.0   \n",
      "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...         NaN         NaN   \n",
      "\n",
      "   2015-07-03  2015-07-04  2015-07-05  2015-07-06  2015-07-07  2015-07-08  \\\n",
      "0         5.0        13.0        14.0         9.0         9.0        22.0   \n",
      "1        15.0        18.0        11.0        13.0        22.0        11.0   \n",
      "2         1.0         1.0         0.0         4.0         0.0         3.0   \n",
      "3        10.0        94.0         4.0        26.0        14.0         9.0   \n",
      "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   2015-07-09  ...  2016-12-22  2016-12-23  2016-12-24  2016-12-25  \\\n",
      "0        26.0  ...        32.0        63.0        15.0        26.0   \n",
      "1        10.0  ...        17.0        42.0        28.0        15.0   \n",
      "2         4.0  ...         3.0         1.0         1.0         7.0   \n",
      "3        11.0  ...        32.0        10.0        26.0        27.0   \n",
      "4         NaN  ...        48.0         9.0        25.0        13.0   \n",
      "\n",
      "   2016-12-26  2016-12-27  2016-12-28  2016-12-29  2016-12-30  2016-12-31  \n",
      "0        14.0        20.0        22.0        19.0        18.0        20.0  \n",
      "1         9.0        30.0        52.0        45.0        26.0        20.0  \n",
      "2         4.0         4.0         6.0         3.0         4.0        17.0  \n",
      "3        16.0        11.0        17.0        19.0        10.0        11.0  \n",
      "4         3.0        11.0        27.0        13.0        36.0        10.0  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145063 entries, 0 to 145062\n",
      "Columns: 551 entries, Page to 2016-12-31\n",
      "dtypes: float64(550), object(1)\n",
      "memory usage: 609.8+ MB\n",
      "None\n",
      "         2015-07-01    2015-07-02    2015-07-03    2015-07-04    2015-07-05  \\\n",
      "count  1.243230e+05  1.242470e+05  1.245190e+05  1.244090e+05  1.244040e+05   \n",
      "mean   1.195857e+03  1.204004e+03  1.133676e+03  1.170437e+03  1.217769e+03   \n",
      "std    7.275352e+04  7.421515e+04  6.961022e+04  7.257351e+04  7.379612e+04   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    1.300000e+01  1.300000e+01  1.200000e+01  1.300000e+01  1.400000e+01   \n",
      "50%    1.090000e+02  1.080000e+02  1.050000e+02  1.050000e+02  1.130000e+02   \n",
      "75%    5.240000e+02  5.190000e+02  5.040000e+02  4.870000e+02  5.400000e+02   \n",
      "max    2.038124e+07  2.075219e+07  1.957397e+07  2.043964e+07  2.077211e+07   \n",
      "\n",
      "         2015-07-06    2015-07-07    2015-07-08    2015-07-09    2015-07-10  \\\n",
      "count  1.245800e+05  1.243990e+05  1.247690e+05  1.248190e+05  1.247210e+05   \n",
      "mean   1.290273e+03  1.239137e+03  1.193092e+03  1.197992e+03  1.189651e+03   \n",
      "std    8.054448e+04  7.576288e+04  6.820002e+04  7.149717e+04  7.214536e+04   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    1.100000e+01  1.300000e+01  1.300000e+01  1.400000e+01  1.400000e+01   \n",
      "50%    1.130000e+02  1.150000e+02  1.170000e+02  1.150000e+02  1.130000e+02   \n",
      "75%    5.550000e+02  5.510000e+02  5.540000e+02  5.490000e+02  5.450000e+02   \n",
      "max    2.254467e+07  2.121089e+07  1.910791e+07  1.999385e+07  2.020182e+07   \n",
      "\n",
      "       ...    2016-12-22    2016-12-23    2016-12-24    2016-12-25  \\\n",
      "count  ...  1.412100e+05  1.414790e+05  1.418740e+05  1.413190e+05   \n",
      "mean   ...  1.394096e+03  1.377482e+03  1.393099e+03  1.523740e+03   \n",
      "std    ...  8.574880e+04  7.732794e+04  8.478533e+04  8.752210e+04   \n",
      "min    ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    ...  2.200000e+01  2.200000e+01  2.000000e+01  2.100000e+01   \n",
      "50%    ...  1.490000e+02  1.430000e+02  1.320000e+02  1.450000e+02   \n",
      "75%    ...  6.070000e+02  5.980000e+02  5.690000e+02  6.280000e+02   \n",
      "max    ...  2.420108e+07  2.253925e+07  2.505662e+07  2.586575e+07   \n",
      "\n",
      "         2016-12-26    2016-12-27    2016-12-28    2016-12-29    2016-12-30  \\\n",
      "count  1.411450e+05  1.413620e+05  1.412410e+05  1.412370e+05  1.414280e+05   \n",
      "mean   1.679607e+03  1.678302e+03  1.633966e+03  1.684308e+03  1.467943e+03   \n",
      "std    9.794534e+04  9.232482e+04  9.185831e+04  9.014266e+04  8.155481e+04   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    2.200000e+01  2.300000e+01  2.400000e+01  2.300000e+01  2.300000e+01   \n",
      "50%    1.600000e+02  1.620000e+02  1.630000e+02  1.600000e+02  1.540000e+02   \n",
      "75%    6.590000e+02  6.680000e+02  6.540000e+02  6.490000e+02  6.350000e+02   \n",
      "max    2.834288e+07  2.691699e+07  2.702505e+07  2.607382e+07  2.436397e+07   \n",
      "\n",
      "         2016-12-31  \n",
      "count  1.415980e+05  \n",
      "mean   1.478282e+03  \n",
      "std    8.873567e+04  \n",
      "min    0.000000e+00  \n",
      "25%    2.100000e+01  \n",
      "50%    1.360000e+02  \n",
      "75%    5.610000e+02  \n",
      "max    2.614954e+07  \n",
      "\n",
      "[8 rows x 550 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"./Data/train_1.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows and summary info\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Cleaning Data\n",
    "\n",
    "Clean the dataset field where if the specific page blank threshold is more than 1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "missing_threshold = 0.05\n",
    "date_columns = df.columns[1:]  # to avoid first column 'Page'\n",
    "\n",
    "df['missing_percentage'] = df[date_columns].isnull().mean(axis=1)\n",
    "\n",
    "# Filter out\n",
    "df_cleaned = df[df['missing_percentage'] < missing_threshold]\n",
    "\n",
    "# Drop 'missing_percentage'\n",
    "df_cleaned = df_cleaned.drop(columns=['missing_percentage'])\n",
    "\n",
    "output_file_path = \"cleaned_data.csv\"\n",
    "df_cleaned.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Filling Data\n",
    "\n",
    "Populating the dataset fields where blank data is present with the average of page visits for that month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled data saved to filled_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"cleaned_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "df.columns = ['Page'] + pd.to_datetime(df.columns[1:]).strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "# Set 'Page' column as index temporarily for easier handling\n",
    "df.set_index('Page', inplace=True)\n",
    "\n",
    "# Transpose the DataFrame to work with dates as the index\n",
    "df_transposed = df.transpose()\n",
    "df_transposed.index = pd.to_datetime(df_transposed.index)\n",
    "\n",
    "# Resample data to monthly frequency and calculate the mean for each page, then round to integers\n",
    "monthly_avg = df_transposed.resample('ME').mean().round().astype(int)\n",
    "\n",
    "# Backfill missing data using the monthly average for each page\n",
    "for date, row in df_transposed.iterrows():\n",
    "    month = date.strftime('%Y-%m')\n",
    "    # Ensure we only use the Series for the correct month\n",
    "    if month in monthly_avg.index.strftime('%Y-%m'):\n",
    "        # Get the monthly average as a Series for that month (already converted to integers)\n",
    "        month_avg_series = monthly_avg.loc[monthly_avg.index.strftime('%Y-%m') == month].iloc[0]\n",
    "        # Fill missing values in this row with the integer monthly average for each page\n",
    "        df_transposed.loc[date] = row.fillna(month_avg_series)\n",
    "\n",
    "# Transpose back to original format\n",
    "df_filled = df_transposed.transpose().reset_index()\n",
    "\n",
    "# Save the updated DataFrame\n",
    "output_file_path = \"filled_data.csv\"\n",
    "df_filled.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Filled data saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Calculate Min, Max, and Range Values\n",
    "\n",
    "For each page, calculate the minimum, maximum, and range of values to understand the spread.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Min_Value   Max_Value       Range\n",
      "2015-07-01 00:00:00        0.0  20381245.0  20381245.0\n",
      "2015-07-02 00:00:00        0.0  20752194.0  20752194.0\n",
      "2015-07-03 00:00:00        0.0  19573967.0  19573967.0\n",
      "2015-07-04 00:00:00        0.0  20439645.0  20439645.0\n",
      "2015-07-05 00:00:00        0.0  20772109.0  20772109.0\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./filled_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Selecting only the numerical columns\n",
    "numeric_cols = df.columns[1:]  # first column is 'Page'\n",
    "\n",
    "# Transpose back temporarily to calculate row-based min, max, and range\n",
    "df_temp = df[numeric_cols].T  # Transpose for calculation convenience\n",
    "df_temp['Min_Value'] = df_temp.min(axis=1)\n",
    "df_temp['Max_Value'] = df_temp.max(axis=1)\n",
    "df_temp['Range'] = df_temp['Max_Value'] - df_temp['Min_Value']\n",
    "\n",
    "# Display min, max, and range for each page\n",
    "print(df_temp[['Min_Value', 'Max_Value', 'Range']].head())\n",
    "\n",
    "# Transpose back to original for further time series analysis\n",
    "df = df_temp.drop(columns=['Min_Value', 'Max_Value', 'Range']).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Min-Max Normalizing data\n",
    "\n",
    "Normalize values between 0 and 1 to standardize across different pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized data has been saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Selecting only the numerical columns\n",
    "numeric_cols = df.columns[1:]  # first column 'Page'\n",
    "\n",
    "# 1. Min-Max Normalization\n",
    "df_min_max_norm = df.copy()\n",
    "df_min_max_norm[numeric_cols] = (df[numeric_cols] - df[numeric_cols].min()) / (df[numeric_cols].max() - df[numeric_cols].min())\n",
    "# Export to CSV\n",
    "df_min_max_norm.to_csv(\"min_max_normalized_data.csv\", index=False)\n",
    "\n",
    "# Displaying the normalized data\n",
    "# print(\"Data after Min-Max Normalization:\")\n",
    "# print(df_min_max_norm[['Page'] + list(numeric_cols)].head())\n",
    "\n",
    "print(\"Normalized data has been saved to CSV files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
